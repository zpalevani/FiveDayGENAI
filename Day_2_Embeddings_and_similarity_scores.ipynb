{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "name": "Day 2 - Embeddings and similarity scores",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zpalevani/FiveDayGENAI/blob/main/Day_2_Embeddings_and_similarity_scores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2025 Google LLC."
      ],
      "metadata": {
        "id": "n01FwvRNeU3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": true
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-31T10:17:04.373398Z",
          "iopub.execute_input": "2025-03-31T10:17:04.373801Z",
          "iopub.status.idle": "2025-03-31T10:17:04.40131Z",
          "shell.execute_reply.started": "2025-03-31T10:17:04.373719Z",
          "shell.execute_reply": "2025-03-31T10:17:04.400163Z"
        },
        "id": "8Q3Q4FUpeU3j"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Day 2 - Embeddings and similarity scores\n",
        "\n",
        "Welcome back to the Kaggle 5-day Generative AI course!\n",
        "\n",
        "In this notebook you will use the Gemini API's embedding endpoint to explore similarity scores.\n",
        "\n",
        "**NOTE**: The Day 1 notebook contains lots of information for getting set up with Kaggle Notebooks. If you are having any issues, please [check out the troubleshooting steps there](https://www.kaggle.com/code/markishere/day-1-prompting#Get-started-with-Kaggle-notebooks).\n",
        "\n",
        "## For help\n",
        "\n",
        "**Common issues are covered in the [FAQ and troubleshooting guide](https://www.kaggle.com/code/markishere/day-0-troubleshooting-and-faqs).**\n"
      ],
      "metadata": {
        "id": "u8QTQ5viA7S0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the SDK"
      ],
      "metadata": {
        "id": "GflcN2KzBIr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -qqy jupyterlab kfp  # Remove unused conflicting packages\n",
        "!pip install -U -q \"google-genai==1.7.0\""
      ],
      "metadata": {
        "id": "rRDDcLfmBIVs",
        "execution": {
          "iopub.status.busy": "2025-03-31T10:17:04.403927Z",
          "iopub.execute_input": "2025-03-31T10:17:04.404389Z",
          "iopub.status.idle": "2025-03-31T10:17:24.015864Z",
          "shell.execute_reply.started": "2025-03-31T10:17:04.404341Z",
          "shell.execute_reply": "2025-03-31T10:17:24.014582Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "genai.__version__"
      ],
      "metadata": {
        "id": "9Q5GpJkIBNyE",
        "execution": {
          "iopub.status.busy": "2025-03-31T10:17:24.017388Z",
          "iopub.execute_input": "2025-03-31T10:17:24.017709Z",
          "iopub.status.idle": "2025-03-31T10:17:25.373986Z",
          "shell.execute_reply.started": "2025-03-31T10:17:24.017679Z",
          "shell.execute_reply": "2025-03-31T10:17:25.372933Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
        "\n",
        "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
        "\n",
        "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
      ],
      "metadata": {
        "id": "3t1owWKbBCwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "B0GMitJlA3mE",
        "execution": {
          "iopub.status.busy": "2025-03-31T10:17:25.375491Z",
          "iopub.execute_input": "2025-03-31T10:17:25.375948Z",
          "iopub.status.idle": "2025-03-31T10:17:25.566544Z",
          "shell.execute_reply.started": "2025-03-31T10:17:25.375916Z",
          "shell.execute_reply": "2025-03-31T10:17:25.565422Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n",
        "\n",
        "![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)"
      ],
      "metadata": {
        "id": "nnTPN1x2eU3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore available models\n",
        "\n",
        "You will be using the [`embedContent`](https://ai.google.dev/api/embeddings#method:-models.embedcontent) API method to calculate batch embeddings in this guide. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. You can also find more information about the embedding models on [the models page](https://ai.google.dev/gemini-api/docs/models/gemini#text-embedding)."
      ],
      "metadata": {
        "id": "Sp_8uANnLlyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "for model in client.models.list():\n",
        "  if 'embedContent' in model.supported_actions:\n",
        "    print(model.name)"
      ],
      "metadata": {
        "id": "7l2CClM0LllM",
        "execution": {
          "iopub.status.busy": "2025-03-31T10:17:25.567991Z",
          "iopub.execute_input": "2025-03-31T10:17:25.56844Z",
          "iopub.status.idle": "2025-03-31T10:17:25.805637Z",
          "shell.execute_reply.started": "2025-03-31T10:17:25.56839Z",
          "shell.execute_reply": "2025-03-31T10:17:25.804538Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate similarity scores\n",
        "\n",
        "This example embeds some variations on the pangram, `The quick brown fox jumps over the lazy dog`, including spelling mistakes and shortenings of the phrase. Another pangram and a somewhat unrelated phrase have been included for comparison.\n",
        "\n",
        "In this task, you are going to use the embeddings to calculate similarity scores, so the `task_type` for these embeddings is `semantic_similarity`. Check out the [API reference](https://ai.google.dev/api/embeddings#v1beta.TaskType) for the full list of tasks."
      ],
      "metadata": {
        "id": "zmGec4TqLF5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    'The quick brown fox jumps over the lazy dog.',\n",
        "    'The quick rbown fox jumps over the lazy dog.',\n",
        "    'teh fast fox jumps over the slow woofer.',\n",
        "    'a quick brown fox jmps over lazy dog.',\n",
        "    'brown fox jumping over dog',\n",
        "    'fox > dog',\n",
        "    # Alternative pangram for comparison:\n",
        "    'The five boxing wizards jump quickly.',\n",
        "    # Unrelated text, also for comparison:\n",
        "    'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus et hendrerit massa. Sed pulvinar, nisi a lobortis sagittis, neque risus gravida dolor, in porta dui odio vel purus.',\n",
        "]\n",
        "\n",
        "\n",
        "response = client.models.embed_content(\n",
        "    model='models/text-embedding-004',\n",
        "    contents=texts,\n",
        "    config=types.EmbedContentConfig(task_type='semantic_similarity'))"
      ],
      "metadata": {
        "id": "PJoihtRALFdL",
        "execution": {
          "iopub.status.busy": "2025-03-31T10:17:25.806831Z",
          "iopub.execute_input": "2025-03-31T10:17:25.807163Z",
          "iopub.status.idle": "2025-03-31T10:17:27.44493Z",
          "shell.execute_reply.started": "2025-03-31T10:17:25.807132Z",
          "shell.execute_reply": "2025-03-31T10:17:27.44377Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a short helper function that will make it easier to display longer embedding texts in our visualisation."
      ],
      "metadata": {
        "id": "dQ18jYuPeU3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def truncate(t: str, limit: int = 50) -> str:\n",
        "  \"\"\"Truncate labels to fit on the chart.\"\"\"\n",
        "  if len(t) > limit:\n",
        "    return t[:limit-3] + '...'\n",
        "  else:\n",
        "    return t\n",
        "\n",
        "truncated_texts = [truncate(t) for t in texts]"
      ],
      "metadata": {
        "id": "QnCDyQZdOQ8M",
        "execution": {
          "iopub.status.busy": "2025-03-31T10:17:27.448381Z",
          "iopub.execute_input": "2025-03-31T10:17:27.449113Z",
          "iopub.status.idle": "2025-03-31T10:17:27.455756Z",
          "shell.execute_reply.started": "2025-03-31T10:17:27.449045Z",
          "shell.execute_reply": "2025-03-31T10:17:27.454871Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "A similarity score of two embedding vectors can be obtained by calculating their inner product. If $\\mathbf{u}$ is the first embedding vector, and $\\mathbf{v}$ the second, this is $\\mathbf{u}^T \\mathbf{v}$. As the API provides embedding vectors that are normalised to unit length, this is also the cosine similarity.\n",
        "\n",
        "This score can be computed across all embeddings through the matrix self-multiplication: `df @ df.T`.\n",
        "\n",
        "Note that the range from 0.0 (completely dissimilar) to 1.0 (completely similar) is depicted in the heatmap from light (0.0) to dark (1.0)."
      ],
      "metadata": {
        "id": "ARqdVQN6R1Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Set up the embeddings in a dataframe.\n",
        "df = pd.DataFrame([e.values for e in response.embeddings], index=truncated_texts)\n",
        "# Perform the similarity calculation\n",
        "sim = df @ df.T\n",
        "# Draw!\n",
        "sns.heatmap(sim, vmin=0, vmax=1, cmap=\"Greens\");"
      ],
      "metadata": {
        "id": "ADlivURDM1mY",
        "execution": {
          "iopub.status.busy": "2025-03-31T10:17:27.457881Z",
          "iopub.execute_input": "2025-03-31T10:17:27.45921Z",
          "iopub.status.idle": "2025-03-31T10:17:29.409307Z",
          "shell.execute_reply.started": "2025-03-31T10:17:27.459162Z",
          "shell.execute_reply": "2025-03-31T10:17:29.408197Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see the scores for a particular term directly by looking it up in the dataframe."
      ],
      "metadata": {
        "id": "xpvA8jzHoQhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sim['The quick brown fox jumps over the lazy dog.'].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "Cpbjryx3oU5Z",
        "execution": {
          "iopub.status.busy": "2025-03-31T10:17:29.411076Z",
          "iopub.execute_input": "2025-03-31T10:17:29.41178Z",
          "iopub.status.idle": "2025-03-31T10:17:29.423236Z",
          "shell.execute_reply.started": "2025-03-31T10:17:29.41173Z",
          "shell.execute_reply": "2025-03-31T10:17:29.422017Z"
        },
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try exploring the embeddings of your own datasets, or explore those available in [Kaggle datasets](https://www.kaggle.com/datasets)."
      ],
      "metadata": {
        "id": "e9JSLLsAeU32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further reading\n",
        "\n",
        "* Explore [search re-ranking using embeddings](https://github.com/google-gemini/cookbook/blob/main/examples/Search_reranking_using_embeddings.ipynb) with the Wikipedia API\n",
        "* Perform [anomaly detection using embeddings](https://github.com/google-gemini/cookbook/blob/main/examples/Anomaly_detection_with_embeddings.ipynb)\n",
        "\n",
        "*- [Mark McD](https://linktr.ee/markmcd)*"
      ],
      "metadata": {
        "id": "asDEEGOppb9f"
      }
    }
  ]
}